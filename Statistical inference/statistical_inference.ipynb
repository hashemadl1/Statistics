{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f979377b-d100-4db8-871a-7000c7ead54f",
   "metadata": {},
   "source": [
    "\n",
    "# Statistical Inference:\n",
    "\n",
    "## An In-Depth Explanation\n",
    "\n",
    "Statistical inference is a method of making decisions about the parameters of a population based on random sampling. It helps to assess the relationship between the dependent and independent variables. The purpose of statistical inference is to estimate the uncertainty or sample-to-sample variation. Essentially, statistical inference uses data analysis to infer properties of an underlying probability distribution.\n",
    "\n",
    "## Key Components of Statistical Inference:\n",
    "\n",
    "1. **Population and Sample:**\n",
    "   - **Population:** The entire set of individuals or items that we are interested in studying.\n",
    "   - **Sample:** A subset of the population, selected randomly to make inferences about the population.\n",
    "\n",
    "2. **Parameters and Statistics:**\n",
    "   - **Parameter:** A numerical characteristic of the population (e.g., population mean, population variance).\n",
    "   - **Statistic:** A numerical characteristic of the sample (e.g., sample mean, sample variance) used to estimate the population parameter.\n",
    "\n",
    "## Methods of Statistical Inference:\n",
    "\n",
    "1. **Point Estimation:**\n",
    "   - **Definition:** Point estimation involves estimating the value of a population parameter using a single value or point.\n",
    "   - **Example:** Suppose we want to estimate the average height of all adult males in a city. We take a random sample of 100 adult males, measure their heights, and calculate the sample mean. This sample mean is our point estimate of the population mean.\n",
    "\n",
    "2. **Interval Estimation (Confidence Intervals):**\n",
    "   - **Definition:** Interval estimation involves estimating the value of a population parameter using a range of values, known as a confidence interval.\n",
    "   - **Example:** Continuing with the height example, instead of giving a single estimate, we might calculate a 95% confidence interval, which provides a range within which we are 95% confident the true population mean lies. For instance, the 95% confidence interval might be [170 cm, 180 cm].\n",
    "\n",
    "3. **Hypothesis Testing:**\n",
    "   - **Definition:** Hypothesis testing involves making decisions about the population parameters based on sample data.\n",
    "   - **Example:** Suppose we want to test if the average height of adult males in the city is 175 cm. We set up two hypotheses: the null hypothesis (H0: the mean height is 175 cm) and the alternative hypothesis (H1: the mean height is not 175 cm). We then collect a sample, calculate the test statistic, and use it to determine whether to reject the null hypothesis.\n",
    "\n",
    "## Example Scenarios:\n",
    "\n",
    "1. **Medical Research:**\n",
    "   - **Scenario:** A pharmaceutical company wants to test if a new drug is effective in reducing blood pressure.\n",
    "   - **Process:** They conduct a clinical trial with a sample of patients and measure their blood pressure before and after administering the drug. Using statistical inference, they can determine if the observed reduction in blood pressure is statistically significant and can be generalized to the entire population.\n",
    "\n",
    "2. **Quality Control:**\n",
    "   - **Scenario:** A factory wants to ensure that the average weight of their packaged products is 500 grams.\n",
    "   - **Process:** They take random samples of the products and measure their weights. Using statistical inference, they can test if the average weight of the sampled products deviates significantly from 500 grams and make decisions about the production process.\n",
    "\n",
    "3. **Social Sciences:**\n",
    "   - **Scenario:** A researcher wants to study the relationship between education level and income.\n",
    "   - **Process:** They collect data from a sample of individuals, analyze the data to find correlations, and use statistical inference to make conclusions about the broader population.\n",
    "\n",
    "## Contrasting Descriptive and Inferential Statistics:\n",
    "\n",
    "- **Descriptive Statistics:** \n",
    "  - Focuses on summarizing and describing the properties of the observed data.\n",
    "  - Example: Calculating the mean, median, mode, and standard deviation of the sample data.\n",
    "  \n",
    "- **Inferential Statistics:**\n",
    "  - Focuses on making inferences about the population based on the sample data.\n",
    "  - Example: Estimating population parameters, constructing confidence intervals, and conducting hypothesis tests.\n",
    "\n",
    "## Machine Learning Context:\n",
    "\n",
    "In machine learning, the term \"inference\" is sometimes used to mean making predictions by evaluating an already trained model. Here, the term \"training\" or \"learning\" refers to the process of inferring properties of the model, while \"inference\" refers to using the model to make predictions.\n",
    "\n",
    "- **Training:** Building a model by learning from a training dataset.\n",
    "- **Inference:** Using the trained model to make predictions on new data.\n",
    "- **Predictive Inference:** Combining statistical inference with machine learning to make predictions and quantify the uncertainty of those predictions.\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "Statistical inference is a powerful tool for making decisions and drawing conclusions about a population based on sample data. By understanding the principles of point estimation, interval estimation, and hypothesis testing, researchers can make informed decisions and provide valuable insights across various fields, including medicine, quality control, social sciences, and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a4fe2-8500-4452-bddc-911506367245",
   "metadata": {},
   "source": [
    "## Description of the T-Test in Statistical Inference\n",
    "\n",
    "A t-test is a statistical test used to determine if there is a significant difference between the means of two groups, which may be related in certain features. It is a type of inferential statistics used to decide if a null hypothesis can be rejected based on the sample data. The test helps to understand whether the differences observed in sample data are due to chance or if they reflect true differences in the population.\n",
    "\n",
    "### Types of T-Tests\n",
    "\n",
    "1. **One-Sample T-Test**: Determines whether the mean of a single sample is significantly different from a known or hypothesized population mean.\n",
    "2. **Independent Two-Sample T-Test**: Compares the means of two independent groups to see if there is evidence that the associated population means are significantly different.\n",
    "3. **Paired Sample T-Test**: Compares means from the same group at different times (say, before and after a treatment) or from matched pairs.\n",
    "\n",
    "### Hypotheses in T-Tests\n",
    "\n",
    "- **Null Hypothesis (H0)**: Assumes that there is no significant difference between the means of the two groups.\n",
    "- **Alternative Hypothesis (H1)**: Assumes that there is a significant difference between the means of the two groups.\n",
    "\n",
    "### Hands-on Examples\n",
    "\n",
    "#### Example 1: One-Sample T-Test\n",
    "\n",
    "Suppose we have a sample of students' test scores and we want to determine if their mean score is significantly different from the population mean score of 70.\n",
    "\n",
    "**Data:**\n",
    "```\n",
    "Sample Scores: [68, 72, 74, 65, 70, 69, 75, 67]\n",
    "Population Mean: 70\n",
    "```\n",
    "\n",
    "**Hypotheses:**\n",
    "- H0: The sample mean is equal to the population mean (μ = 70).\n",
    "- H1: The sample mean is not equal to the population mean (μ ≠ 70).\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Sample data\n",
    "sample_scores <- c(68, 72, 74, 65, 70, 69, 75, 67)\n",
    "\n",
    "# Population mean\n",
    "population_mean <- 70\n",
    "\n",
    "# One-sample t-test\n",
    "t_test_result <- t.test(sample_scores, mu = population_mean)\n",
    "\n",
    "# Print the result\n",
    "print(t_test_result)\n",
    "```\n",
    "\n",
    "#### Example 2: Independent Two-Sample T-Test\n",
    "\n",
    "Suppose we have test scores of two different groups of students and we want to determine if there is a significant difference between their mean scores.\n",
    "\n",
    "**Data:**\n",
    "```\n",
    "Group 1 Scores: [85, 90, 88, 75, 78]\n",
    "Group 2 Scores: [82, 87, 86, 80, 79]\n",
    "```\n",
    "\n",
    "**Hypotheses:**\n",
    "- H0: The means of the two groups are equal (μ1 = μ2).\n",
    "- H1: The means of the two groups are not equal (μ1 ≠ μ2).\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Sample data\n",
    "group1_scores <- c(85, 90, 88, 75, 78)\n",
    "group2_scores <- c(82, 87, 86, 80, 79)\n",
    "\n",
    "# Independent two-sample t-test\n",
    "t_test_result <- t.test(group1_scores, group2_scores)\n",
    "\n",
    "# Print the result\n",
    "print(t_test_result)\n",
    "```\n",
    "\n",
    "#### Example 3: Paired Sample T-Test\n",
    "\n",
    "Suppose we have test scores of the same group of students before and after a training program and we want to determine if the training program has significantly affected their scores.\n",
    "\n",
    "**Data:**\n",
    "```\n",
    "Before Training: [65, 70, 75, 60, 72]\n",
    "After Training: [68, 74, 78, 65, 75]\n",
    "```\n",
    "\n",
    "**Hypotheses:**\n",
    "- H0: The mean difference between the pairs is zero (μd = 0).\n",
    "- H1: The mean difference between the pairs is not zero (μd ≠ 0).\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Sample data\n",
    "before_training <- c(65, 70, 75, 60, 72)\n",
    "after_training <- c(68, 74, 78, 65, 75)\n",
    "\n",
    "# Paired sample t-test\n",
    "t_test_result <- t.test(before_training, after_training, paired = TRUE)\n",
    "\n",
    "# Print the result\n",
    "print(t_test_result)\n",
    "```\n",
    "\n",
    "These examples illustrate the application of different types of t-tests using R, which helps in making informed decisions based on sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2664f9af-51fd-455f-92c4-432407e54b21",
   "metadata": {},
   "source": [
    "## Description of Normal Distribution in Statistical Inference\n",
    "\n",
    "### Normal Distribution\n",
    "\n",
    "The normal distribution, also known as the Gaussian distribution, is a continuous probability distribution that is symmetric about its mean. It is characterized by its bell-shaped curve, where the mean, median, and mode of the distribution are all equal. The shape and position of the normal distribution are defined by two parameters:\n",
    "\n",
    "1. **Mean (μ)**: The central value around which the distribution is symmetric.\n",
    "2. **Standard Deviation (σ)**: Measures the spread or dispersion of the distribution. A smaller standard deviation indicates that the data points are closer to the mean, while a larger standard deviation indicates that the data points are more spread out.\n",
    "\n",
    "The probability density function (PDF) of a normal distribution is given by:\n",
    "\n",
    "\\[ f(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\]\n",
    "\n",
    "### Properties of Normal Distribution\n",
    "\n",
    "1. **Symmetry**: The distribution is symmetric around the mean.\n",
    "2. **Bell Shape**: The highest point is at the mean, and it tapers off equally on both sides.\n",
    "3. **Empirical Rule (68-95-99.7 Rule)**:\n",
    "   - About 68% of the data falls within one standard deviation of the mean.\n",
    "   - About 95% of the data falls within two standard deviations of the mean.\n",
    "   - About 99.7% of the data falls within three standard deviations of the mean.\n",
    "\n",
    "### Use in Statistical Inference\n",
    "\n",
    "Normal distribution plays a crucial role in statistical inference due to the following reasons:\n",
    "\n",
    "1. **Central Limit Theorem (CLT)**: The CLT states that the sampling distribution of the sample mean will approach a normal distribution, regardless of the original distribution of the data, as the sample size becomes large. This allows statisticians to make inferences about population parameters using sample data.\n",
    "2. **Hypothesis Testing**: Many statistical tests, such as t-tests and z-tests, assume that the data follows a normal distribution. This assumption allows for the derivation of critical values and p-values to test hypotheses.\n",
    "3. **Confidence Intervals**: When constructing confidence intervals for the mean of a normally distributed population, the normal distribution is used to determine the interval range.\n",
    "4. **Regression Analysis**: In linear regression, the assumption of normally distributed residuals is often made to validate the model and make accurate predictions.\n",
    "\n",
    "### Example of Normal Distribution in Statistical Inference\n",
    "\n",
    "#### Hypothesis Testing with Normal Distribution\n",
    "\n",
    "Suppose we want to test whether the mean height of a population of adult males is 175 cm. We take a sample of 30 individuals and calculate their mean height and standard deviation.\n",
    "\n",
    "**Data:**\n",
    "```\n",
    "Sample Mean (x̄): 178 cm\n",
    "Sample Standard Deviation (s): 8 cm\n",
    "Sample Size (n): 30\n",
    "Population Mean (μ): 175 cm\n",
    "```\n",
    "\n",
    "**Hypotheses:**\n",
    "- H0: The mean height of the population is 175 cm (μ = 175).\n",
    "- H1: The mean height of the population is not 175 cm (μ ≠ 175).\n",
    "\n",
    "To test this hypothesis, we can use a z-test (assuming the population standard deviation is known) or a t-test (if the population standard deviation is unknown). Here, we will use a t-test.\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Sample data\n",
    "sample_mean <- 178\n",
    "population_mean <- 175\n",
    "sample_sd <- 8\n",
    "sample_size <- 30\n",
    "\n",
    "# Calculate the t-value\n",
    "t_value <- (sample_mean - population_mean) / (sample_sd / sqrt(sample_size))\n",
    "\n",
    "# Degrees of freedom\n",
    "df <- sample_size - 1\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value <- 2 * pt(-abs(t_value), df)\n",
    "\n",
    "# Print the t-value and p-value\n",
    "t_value\n",
    "p_value\n",
    "```\n",
    "\n",
    "The t-value and p-value help us determine whether to reject the null hypothesis. If the p-value is less than the significance level (e.g., 0.05), we reject the null hypothesis, indicating that there is a significant difference between the sample mean and the population mean.\n",
    "\n",
    "Normal distribution and its properties are fundamental to various statistical methods, making it an essential concept in the field of statistical inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe18bb71",
   "metadata": {},
   "source": [
    "## Description of the T-Student Distribution:\n",
    "\n",
    "### T-Student Distribution\n",
    "\n",
    "The T-Student distribution, also known simply as the t-distribution, is a probability distribution that is symmetric and bell-shaped, like the normal distribution, but has heavier tails. This means it is more prone to producing values that fall far from its mean. The t-distribution is particularly useful when dealing with small sample sizes or when the population standard deviation is unknown.\n",
    "\n",
    "The t-distribution is defined by its degrees of freedom (df), which are related to the sample size. As the degrees of freedom increase, the t-distribution approaches the normal distribution.\n",
    "\n",
    "### Properties of the T-Student Distribution\n",
    "\n",
    "1. **Symmetry**: The distribution is symmetric around the mean.\n",
    "2. **Heavier Tails**: Compared to the normal distribution, it has heavier tails, which means it is more likely to produce outliers.\n",
    "3. **Degrees of Freedom (df)**: The shape of the t-distribution depends on the degrees of freedom. With more degrees of freedom, the t-distribution becomes closer to the normal distribution.\n",
    "\n",
    "### Use in Statistical Inference\n",
    "\n",
    "The t-distribution is used extensively in inferential statistics, particularly for hypothesis testing and constructing confidence intervals when the sample size is small, and the population standard deviation is unknown. Common applications include:\n",
    "\n",
    "1. **One-Sample t-Test**: Testing if the mean of a single sample differs from a known or hypothesized population mean.\n",
    "2. **Two-Sample t-Test**: Comparing the means of two independent samples.\n",
    "3. **Paired Sample t-Test**: Comparing the means of two related samples.\n",
    "\n",
    "### Hands-on Examples\n",
    "\n",
    "#### Example 1: One-Sample t-Test\n",
    "\n",
    "Suppose we have a sample of weights of a certain species of birds and we want to determine if their mean weight is significantly different from 300 grams.\n",
    "\n",
    "**Data:**\n",
    "```\n",
    "Sample Weights: [310, 305, 295, 285, 300, 290, 315, 320, 298, 305]\n",
    "Population Mean: 300 grams\n",
    "```\n",
    "\n",
    "**Hypotheses:**\n",
    "- H0: The sample mean is equal to the population mean (μ = 300).\n",
    "- H1: The sample mean is not equal to the population mean (μ ≠ 300).\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Sample data\n",
    "sample_weights <- c(310, 305, 295, 285, 300, 290, 315, 320, 298, 305)\n",
    "\n",
    "# Population mean\n",
    "population_mean <- 300\n",
    "\n",
    "# One-sample t-test\n",
    "t_test_result <- t.test(sample_weights, mu = population_mean)\n",
    "\n",
    "# Print the result\n",
    "print(t_test_result)\n",
    "```\n",
    "\n",
    "#### Example 2: Independent Two-Sample t-Test\n",
    "\n",
    "Suppose we have test scores of two different groups of students and we want to determine if there is a significant difference between their mean scores.\n",
    "\n",
    "**Data:**\n",
    "```\n",
    "Group 1 Scores: [85, 90, 88, 75, 78]\n",
    "Group 2 Scores: [82, 87, 86, 80, 79]\n",
    "```\n",
    "\n",
    "**Hypotheses:**\n",
    "- H0: The means of the two groups are equal (μ1 = μ2).\n",
    "- H1: The means of the two groups are not equal (μ1 ≠ μ2).\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Sample data\n",
    "group1_scores <- c(85, 90, 88, 75, 78)\n",
    "group2_scores <- c(82, 87, 86, 80, 79)\n",
    "\n",
    "# Independent two-sample t-test\n",
    "t_test_result <- t.test(group1_scores, group2_scores)\n",
    "\n",
    "# Print the result\n",
    "print(t_test_result)\n",
    "```\n",
    "\n",
    "#### Example 3: Paired Sample t-Test\n",
    "\n",
    "Suppose we have test scores of the same group of students before and after a training program and we want to determine if the training program has significantly affected their scores.\n",
    "\n",
    "**Data:**\n",
    "```\n",
    "Before Training: [65, 70, 75, 60, 72]\n",
    "After Training: [68, 74, 78, 65, 75]\n",
    "```\n",
    "\n",
    "**Hypotheses:**\n",
    "- H0: The mean difference between the pairs is zero (μd = 0).\n",
    "- H1: The mean difference between the pairs is not zero (μd ≠ 0).\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Sample data\n",
    "before_training <- c(65, 70, 75, 60, 72)\n",
    "after_training <- c(68, 74, 78, 65, 75)\n",
    "\n",
    "# Paired sample t-test\n",
    "t_test_result <- t.test(before_training, after_training, paired = TRUE)\n",
    "\n",
    "# Print the result\n",
    "print(t_test_result)\n",
    "```\n",
    "\n",
    "These examples demonstrate how to apply the T-Student distribution in various types of t-tests using R. The t-distribution is an essential tool in statistical inference, especially when dealing with small sample sizes or unknown population standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0202dadc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
